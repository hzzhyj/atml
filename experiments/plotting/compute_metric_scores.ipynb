{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "spiritual-traveler",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.lines as mlines\n",
    "\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('../..'))\n",
    "sys.path.append(module_path+\"/models\")\n",
    "sys.path.append(module_path+\"/train\")\n",
    "sys.path.append(module_path+\"/datasets\")\n",
    "\n",
    "from datasets import train_test_random_split, load_dsprites, CustomDSpritesDataset\n",
    "from entanglement_metric import entanglement_metric_factor_vae, entanglement_metric_beta_vae, compute_mig\n",
    "from beta_vae import Classifier\n",
    "from factor_vae import Discriminator\n",
    "from train import test_beta_vae, test_factor_vae, test_control_vae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "framed-florence",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "toxic-opinion",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "device.type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "sharing-hunter",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss(loss_lists, title):\n",
    "    if not isinstance(loss_lists[0], list):\n",
    "        loss_lists = [loss_lists]\n",
    "    for loss_list in loss_lists:\n",
    "        plt.plot(np.arange(1,len(loss_list)+1, 1), loss_list)\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.title(\"Training \"+title+\" of the classifier over epochs\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "threatened-pepper",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dsprites(\"../../datasets/dsprites.npz\",False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "radio-center",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ = CustomDSpritesDataset(dataset,seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bright-municipality",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = None\n",
    "transform_needs_latents = False\n",
    "\n",
    "# transform = AddUniformNoise(-.1, .1)\n",
    "# transform_needs_latents = False\n",
    "\n",
    "# transform = AddGeneratedNoise(abs_path + \"/datasets/noisenet.pth\", device)\n",
    "# transform_needs_latents = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "appointed-kidney",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train, data_test = train_test_random_split(data_.idx,0.8, seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "proof-curtis",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=64\n",
    "test_loader = DataLoader(data_test, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "lyric-museum",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = \"normal_dataset_bernoulli_cnn_models\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "common-excess",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cnnbetavae_epochs50_gamma4_lrvae0.0001_lrd0.0001.dat',\n",
       " 'cnnfactorvae_epochs50_gamma20_lrvae0.0001_lrd1e-05.dat']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_names = [f for f in os.listdir('../trained_models/'+folder) if f[-4:] =='.dat' ]\n",
    "model_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "resident-beauty",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "recon_losses = []\n",
    "betavae_metric_accuracies=[]\n",
    "factorvae_metric_accuracies=[]\n",
    "mig_scores = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hazardous-minnesota",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 1: cnnbetavae_epochs50_gamma4_lrvae0.0001_lrd0.0001.dat\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2304 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ireneburger/opt/anaconda3/envs/atml/lib/python3.8/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reconstruction loss: 45.15021482772298\n",
      "accuracies : [0.6779999999999999, 0.692, 0.65, 0.632, 0.646]\n",
      "[[[ 0.   2.2  3.4  8.4  0.   0.2]\n",
      "  [ 0.  16.2  6.   8.2  3.8  0. ]\n",
      "  [ 0.   0.   3.8 25.   0.   0. ]\n",
      "  [ 0.   8.   7.2  1.4 16.6 80. ]\n",
      "  [ 0.   1.6 36.4  2.  12.2 10.6]\n",
      "  [ 0.  30.6 15.  15.4  0.  11.2]\n",
      "  [ 0.  44.   3.6 16.4  0.   0.8]\n",
      "  [ 0.   0.2  4.6 16.8  0.   0. ]\n",
      "  [ 0.   0.   6.4  4.4  0.   0.2]\n",
      "  [ 0.   3.   7.4  1.  65.8  0. ]]]\n",
      "0.6596\n",
      "Factor Vae metric: \n",
      "Accuracy: 0.6596\n",
      "Beta Vae metric: \n"
     ]
    }
   ],
   "source": [
    "i=1\n",
    "\n",
    "for name in model_names:\n",
    "    model = torch.load('../trained_models/'+folder+\"/\"+name, map_location=device)\n",
    "    print(\"model \"+str(i)+\": \"+name)\n",
    "    if \"betavae\" in name:\n",
    "        recon_loss = test_beta_vae(model, test_loader,0, 'bernoulli',data_, transform, transform_needs_latents, device=device)\n",
    "    elif \"controlvae\" in name:\n",
    "        recon_loss = test_control_vae(model, test_loader, 'bernoulli',data_, transform, transform_needs_latents, device=device)\n",
    "    elif \"factorvae\" in name:\n",
    "        discriminator = Discriminator()\n",
    "        recon_loss = test_factor_vae(model,discriminator, test_loader,0, 'bernoulli',data_, transform, transform_needs_latents, device=device)\n",
    "    else:\n",
    "        print(\"Error in the dataset name\")\n",
    "        break\n",
    "    recon_losses.append(recon_loss)\n",
    "    print(\"Reconstruction loss: \"+str(recon_loss))\n",
    "    accuracies = entanglement_metric_factor_vae(model, data_, 500, 200, random_seeds=5, device = device,seed=seed)\n",
    "    factorvae_metric_accuracies.append(accuracies)\n",
    "    print(\"Factor Vae metric: \")\n",
    "    print(\"Accuracy: \"+str(np.mean(accuracies)))\n",
    "    print(\"Beta Vae metric: \")\n",
    "    torch.manual_seed(seed)\n",
    "    classifier = Classifier()\n",
    "    classifier.to(device)\n",
    "    optimizer = torch.optim.Adagrad(classifier.parameters(), lr=1e-2)\n",
    "    train_losses, train_accuracies, test_accuracies = entanglement_metric_beta_vae(model, classifier, optimizer, 10000,  data_, 1000, 50, random_seeds=5, device = device,seed=seed)\n",
    "    betavae_metric_accuracies.append(test_accuracies)\n",
    "    print(\"Accuracy: \"+str(np.mean(test_accuracies)))\n",
    "    plot_loss(train_losses, \"NLL Loss\")\n",
    "    plot_loss(train_accuracies, \"Accuracy\")\n",
    "    print(\"Mig metric\")\n",
    "    scores = compute_mig(model, data_, num_samples=100000, random_seeds=5, device=device, seed=seed)\n",
    "    mig_scores.append(scores)\n",
    "    print(\"Scores: \"+str(scores))\n",
    "    print(\"Score: \"+str(np.mean(scores)))\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "excessive-sociology",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(folder+\"_model_names.npy\", np.array(model_names))\n",
    "np.save(folder+\"_test_recon_losses.npy\", np.array(recon_losses))\n",
    "np.save(folder+\"_betavaemetric_scores.npy\", np.array(betavae_metric_accuracies))\n",
    "np.save(folder+\"_factorvaemetric_scores.npy\", np.array(factorvae_metric_accuracies))\n",
    "np.save(folder+\"_mig_scores.npy\", np.array(mig_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rocky-trainer",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
