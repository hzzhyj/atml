{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "spiritual-traveler",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.lines as mlines\n",
    "\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('../..'))\n",
    "sys.path.append(module_path+\"/models\")\n",
    "sys.path.append(module_path+\"/train\")\n",
    "sys.path.append(module_path+\"/datasets\")\n",
    "\n",
    "from datasets import train_test_random_split, load_dsprites, CustomDSpritesDataset\n",
    "from entanglement_metric import entanglement_metric_factor_vae, entanglement_metric_beta_vae, compute_mig\n",
    "from beta_vae import Classifier\n",
    "from factor_vae import Discriminator\n",
    "from train import test_beta_vae, test_factor_vae, test_control_vae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "framed-florence",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "toxic-opinion",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "device.type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "sharing-hunter",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss(loss_lists, title):\n",
    "    if not isinstance(loss_lists[0], list):\n",
    "        loss_lists = [loss_lists]\n",
    "    for loss_list in loss_lists:\n",
    "        plt.plot(np.arange(1,len(loss_list)+1, 1), loss_list)\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.title(\"Training \"+title+\" of the classifier over epochs\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "threatened-pepper",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dsprites(\"../../datasets/dsprites.npz\",False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "radio-center",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ = CustomDSpritesDataset(dataset,seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bright-municipality",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = None\n",
    "transform_needs_latents = False\n",
    "\n",
    "# transform = AddUniformNoise(-.1, .1)\n",
    "# transform_needs_latents = False\n",
    "\n",
    "# transform = AddGeneratedNoise(abs_path + \"/datasets/noisenet.pth\", device)\n",
    "# transform_needs_latents = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "appointed-kidney",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train, data_test = train_test_random_split(data_.idx,0.8, seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "proof-curtis",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=64\n",
    "test_loader = DataLoader(data_test, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "lyric-museum",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = \"normal_dataset_gaussian_fc_models\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "common-excess",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['controlvae_epoch50_lr1e2_Cmax10.dat',\n",
       " 'controlvae_epoch50_lr1e2_Cmax8.dat',\n",
       " 'controlvae_epoch50_lr1e2_Cmax12.dat']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_names = [f for f in os.listdir('../trained_models/'+folder) if f[-4:] =='.dat' ]\n",
    "model_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "resident-beauty",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "recon_losses = []\n",
    "betavae_metric_accuracies=[]\n",
    "factorvae_metric_accuracies=[]\n",
    "mig_scores = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hazardous-minnesota",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 1: controlvae_epoch50_lr1e2_Cmax10.dat\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2304 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ireneburger/opt/anaconda3/envs/atml/lib/python3.8/site-packages/torch/nn/functional.py:1709: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "/Users/ireneburger/opt/anaconda3/envs/atml/lib/python3.8/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reconstruction loss: 28.296441567440827\n",
      "accuracies : [0.774, 0.76, 0.808, 0.786, 0.782]\n",
      "[[[  0.    0.    0.    4.6   0.  103. ]\n",
      "  [  0.   75.2   0.   74.2   0.    0. ]\n",
      "  [  0.    0.    0.    2.8   0.    0. ]\n",
      "  [  0.   30.6  93.8   2.2   0.    0. ]\n",
      "  [  0.    0.    0.    1.2   0.    0. ]\n",
      "  [  0.    0.    0.    1.8  98.4   0. ]\n",
      "  [  0.    0.    0.    0.6   0.    0. ]\n",
      "  [  0.    0.    0.    5.    0.    0. ]\n",
      "  [  0.    0.    0.    0.8   0.    0. ]\n",
      "  [  0.    0.    0.    5.8   0.    0. ]]]\n",
      "0.782\n",
      "Factor Vae metric: \n",
      "Accuracy: 0.782\n",
      "Beta Vae metric: \n"
     ]
    }
   ],
   "source": [
    "i=1\n",
    "\n",
    "for name in model_names:\n",
    "    model = torch.load('../trained_models/'+folder+\"/\"+name, map_location=device)\n",
    "    print(\"model \"+str(i)+\": \"+name)\n",
    "    if \"betavae\" in name:\n",
    "        recon_loss = test_beta_vae(model, test_loader,0, 'bernoulli',data_, transform, transform_needs_latents, device=device)\n",
    "    elif \"controlvae\" in name:\n",
    "        recon_loss = test_control_vae(model, test_loader, 'gaussian',data_, transform, transform_needs_latents, device=device)\n",
    "    elif \"factorvae\" in name:\n",
    "        discriminator = Discriminator()\n",
    "        recon_loss = test_factor_vae(model,discriminator, test_loader,0, 'bernoulli',data_, transform, transform_needs_latents, device=device)\n",
    "    else:\n",
    "        print(\"Error in the dataset name\")\n",
    "        break\n",
    "    recon_losses.append(recon_loss)\n",
    "    print(\"Reconstruction loss: \"+str(recon_loss))\n",
    "    accuracies = entanglement_metric_factor_vae(model, data_, 500, 200, random_seeds=5, device = device,seed=seed)\n",
    "    factorvae_metric_accuracies.append(accuracies)\n",
    "    print(\"Factor Vae metric: \")\n",
    "    print(\"Accuracy: \"+str(np.mean(accuracies)))\n",
    "    print(\"Beta Vae metric: \")\n",
    "    torch.manual_seed(seed)\n",
    "    classifier = Classifier()\n",
    "    classifier.to(device)\n",
    "    optimizer = torch.optim.Adagrad(classifier.parameters(), lr=1e-2)\n",
    "    train_losses, train_accuracies, test_accuracies = entanglement_metric_beta_vae(model, classifier, optimizer, 10000,  data_, 1000, 50, random_seeds=5, device = device,seed=seed)\n",
    "    betavae_metric_accuracies.append(test_accuracies)\n",
    "    print(\"Accuracy: \"+str(np.mean(test_accuracies)))\n",
    "    plot_loss(train_losses, \"NLL Loss\")\n",
    "    plot_loss(train_accuracies, \"Accuracy\")\n",
    "    print(\"Mig metric\")\n",
    "    scores = compute_mig(model, data_, num_samples=100000, random_seeds=5, device=device, seed=seed)\n",
    "    mig_scores.append(scores)\n",
    "    print(\"Scores: \"+str(scores))\n",
    "    print(\"Score: \"+str(np.mean(scores)))\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "excessive-sociology",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.805, 0.565, 0.6, 0.51, 0.56],\n",
       " [0.8, 0.56, 0.61, 0.51, 0.56],\n",
       " [0.87, 0.745, 0.805, 0.785, 0.775],\n",
       " [0.77, 0.62, 0.73, 0.69, 0.685],\n",
       " [0.8, 0.555, 0.615, 0.515, 0.56]]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.save(folder+\"_model_names.npy\", np.array(model_names))\n",
    "np.save(folder+\"_test_recon_losses.npy\", np.array(recon_losses))\n",
    "np.save(folder+\"_betavaemetric_scores.npy\", np.array(betavae_metric_accuracies))\n",
    "np.save(folder+\"_factorvaemetric_scores.npy\", np.array(factorvae_metric_accuracies))\n",
    "np.save(folder+\"_mig_scores.npy\", np.array(mig_scores))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
